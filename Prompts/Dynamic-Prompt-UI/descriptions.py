papers = [
    "Attention Is All You Need",
    "BERT: Pre-training of Deep Bidirectional Transformers",
    "GPT-3: Language Models are Few-Shot Learners",
    "Diffusion Models Beat GANs on Image Synthesis",
    "ImageNet Classification with Deep Convolutional Neural Networks",
    "Playing Atari with Deep Reinforcement Learning",
    "Mastering the Game of Go with Deep Neural Networks and Tree Search",
    "YOLOv3: An Incremental Improvement",
    "YOLOv4: Optimal Speed and Accuracy of Object Detection",
    "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
    "R-CNN: Rich feature hierarchies for accurate object detection and semantic segmentation",
    "U-Net: Convolutional Networks for Biomedical Image Segmentation",
    "ResNet: Deep Residual Learning for Image Recognition",
    "VGGNet: Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications",
    "CLIP: Learning Transferable Visual Models From Natural Language Supervision",
    "DINO: Emerging Properties in Self-Supervised Vision Transformers",
    "DETR: End-to-End Object Detection with Transformers",
    "Vision Transformers (ViT): An Image is Worth 16x16 Words",
    "Masked Autoencoders Are Scalable Vision Learners",
    "Pix2Pix: Image-to-Image Translation with Conditional Adversarial Nets",
    "CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks",
    "StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks",
    "StyleGAN2: Analyzing and Improving the Image Quality of StyleGAN",
    "BigGAN: Large Scale GAN Training for High Fidelity Natural Image Synthesis",
    "UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation",
    "DistilBERT: A Distilled Version of BERT",
    "XLNet: Generalized Autoregressive Pretraining for Language Understanding",
    "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
    "T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
    "PaLM: Scaling Language Models with Pathways",
    "LLaMA: Open and Efficient Foundation Language Models",
    "Gemini: Scaling Multimodal Language Models",
    "Flamingo: A Visual Language Model for Few-Shot Learning",
    "BLIP-2: Bootstrapped Language-Image Pretraining with Frozen Image Encoders and Large Language Models",
    "SAM: Segment Anything",
    "Self-Attention with Relative Position Representations",
    "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows",
    "LaMDA: Language Models for Dialog Applications",
    "ChatGPT: Optimizing Language Models for Dialogue",
    "RLHF: Deep Reinforcement Learning from Human Preferences",
    "Gopher: Scaling Language Models for Knowledge-Intensive Tasks",
    "DALLÂ·E: Creating Images from Text Descriptions",
    "Imagen: Photorealistic Text-to-Image Generation",
    "DreamFusion: Text-to-3D using 2D Diffusion",
    "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis",
    "ControlNet: Adding Conditional Control to Text-to-Image Diffusion Models",
    "Segment Anything Model (SAM): A Promptable Image Segmentation",
    "Plan-and-Solve Prompting: Large Language Models are Zero-Shot Planners and Solvers",
    "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
    "Minerva: Solving Quantitative Reasoning Problems with Language Models",
    "AlphaZero: Mastering Games Without Human Knowledge",
    "MuZero: Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model",
    "Dreamer: Reinforcement Learning with World Models",
    "Decision Transformer: Reinforcement Learning via Sequence Modeling",
    "GATO: A Generalist Agent",
    "Whisper: Robust Speech Recognition via Large-Scale Weak Supervision",
    "Tacotron: Towards End-to-End Speech Synthesis",
    "Wav2Vec 2.0: A Framework for Self-Supervised Learning of Speech Representations",
    "SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing",
    "Noisy Student: Training Self-Training with Noisy Student Improves ImageNet Classification",
    "SimCLR: A Simple Framework for Contrastive Learning of Visual Representations",
    "MoCo: Momentum Contrast for Unsupervised Visual Representation Learning",
    "BYOL: Bootstrap Your Own Latent",
    "Barlow Twins: Self-Supervised Learning via Redundancy Reduction",
    "Token Merging: Simple and Effective Speedup of Transformers for Vision",
    "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness",
    "LoRA: Low-Rank Adaptation of Large Language Models",
    "PEFT: Parameter-Efficient Fine-Tuning for NLP",
    "Retrieval-Augmented Generation (RAG): Leveraging External Knowledge for Language Models"
]

styles = [
    "Beginner-Friendly",
    "Technical",
    "Code-Oriented",
    "Mathematical"
]

length = [
    "Short (1-2 paragraphs)",
    "Medium (3-5 paragraphs)",
    "Long (detailed explanation)"
]

msg = """" 
This is a very basic Research Tool which uses an **Open Source Generative model** to summarize various research papers. 
The response is entirely depend upon the prompt which includes:
- **Name of the paper**
- **Length of the response**
- **Format of the response**

Prompt Engineering (Dynamically) has actually been targeted to generate potential summary!


The work has done by **Zara Abrar** F2021266603.
"""
